{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJdEXvveKlw_",
        "outputId": "7b515267-11f9-49cf-b5f7-5eab643f5cb8"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain langchain-core langchain-community pydantic duckduckgo-search langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGVOzFTqLfOf"
      },
      "source": [
        "## Built-in Tool - DuckDuckGo Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# google genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.agents import  create_agent\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model = 'models/gemini-2.5-flash')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K8ez4gVLVua",
        "outputId": "4a367267-f791-49b5-bd7d-4e67b6f29337"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "agent = create_agent(\n",
        "    model=llm,\n",
        "    tools=[search_tool],\n",
        "    system_prompt=\"Search for information and provide accurate answers based on results.\"\n",
        ")\n",
        "\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What is langchain\"}]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HumanMessage(content='What is langchain', additional_kwargs={}, response_metadata={}, id='9248fa5b-386a-4e3f-b3a1-2fdee61ca914')\n",
            "=========================================================================== \n",
            "\n",
            "AIMessage(content='', additional_kwargs={'function_call': {'name': 'duckduckgo_search', 'arguments': '{\"query\": \"langchain\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--b022393e-35d8-431f-8cf4-f5b0269e0513-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'langchain'}, 'id': '93e1fbee-5f0b-41a6-a6c6-4260ac1a782e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 100, 'total_tokens': 180, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 82}})\n",
            "=========================================================================== \n",
            "\n",
            "ToolMessage(content=\"3 days ago - LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications . As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, ... LangChain helps you ship quickly with less code using a pre-built agent architecture and model integrations. LangGraph puts you in control with low-level primitives to build custom agent... Why use LangChain ? LangChain helps developers build applications powered by LLMs through a standard interface for models, embeddings, vector stores, and more. LangChain is an open-source library that provides developers with the necessary tools to create applications powered by large language models (LLMs) [1][2]. It is a framework built... LangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more.\", name='duckduckgo_search', id='1d1268fa-c671-445b-ac9e-ba9c41b1b16e', tool_call_id='93e1fbee-5f0b-41a6-a6c6-4260ac1a782e')\n",
            "=========================================================================== \n",
            "\n",
            "AIMessage(content='LangChain is an open-source software framework designed to help developers build applications powered by large language models (LLMs). It provides tools and a standard interface for integrating LLMs with various components like models, embeddings, and vector stores. LangChain aims to simplify the development of LLM-powered applications, enabling quicker deployment with less code through its pre-built agent architecture and model integrations. Its use cases are broad and include tasks such as document analysis and summarization. LangGraph is a component within LangChain that offers low-level primitives for building custom agents with features like durable execution, streaming, human-in-the-loop interaction, and persistence.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--22425b16-6e72-46c1-9e45-e6a80f0b75fd-0', usage_metadata={'input_tokens': 308, 'output_tokens': 132, 'total_tokens': 440, 'input_token_details': {'cache_read': 0}})\n",
            "=========================================================================== \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(0, 4):\n",
        "    # pprint(dict(result['messages'][i]))\n",
        "    pprint(result['messages'][i])\n",
        "    print('=========================================================================== \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is langchain', additional_kwargs={}, response_metadata={}, id='b123a9a4-1419-44eb-bdfa-12347d0bf7e2'),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'duckduckgo_search', 'arguments': '{\"query\": \"langchain\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--877ccda4-2adf-49e8-8983-bd32918c335b-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'langchain'}, 'id': 'defc2a5a-c871-4995-a1a3-53091bba18e9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 50, 'total_tokens': 130, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 32}}),\n",
              " ToolMessage(content=\"LangChain is a software framework that helps facilitate the integration of large language models into applications. As a language model integration framework, LangChain 's... LangChain helps you ship quickly with less code using a pre-built agent architecture and model integrations. LangGraph puts you in control with low-level primitives to build custom agent... Why use LangChain ? LangChain helps developers build applications powered by LLMs through a standard interface for models, embeddings, vector stores, and more. LangChain is an open-source library that provides developers with the necessary tools to create applications powered by large language models (LLMs) [1][2]. It is a framework built... LangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more.\", name='duckduckgo_search', id='8178abf8-acbe-49a7-b140-1640b8a848d0', tool_call_id='defc2a5a-c871-4995-a1a3-53091bba18e9'),\n",
              " AIMessage(content='LangChain is an open-source software framework designed to simplify the integration of large language models (LLMs) into various applications. It provides developers with tools and a standard interface to build LLM-powered applications, offering features like pre-built agent architectures, model integrations, and low-level primitives for custom agent development. It also supports durable execution, streaming, human-in-the-loop workflows, and persistence.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--7f1cba07-27b5-40fb-8f05-644fa2b7b8a4-0', usage_metadata={'input_tokens': 280, 'output_tokens': 85, 'total_tokens': 365, 'input_token_details': {'cache_read': 0}})]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['messages']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz5qSI-516qS",
        "outputId": "ba42efec-546a-4047-af88-fb15076f9e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "duckduckgo_search\n",
            "A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "{'query': {'description': 'search query to look up', 'title': 'Query', 'type': 'string'}}\n"
          ]
        }
      ],
      "source": [
        "print(search_tool.name)\n",
        "print(search_tool.description)\n",
        "print(search_tool.args) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xnm2Mx1L9WQ"
      },
      "source": [
        "## Built-in Tool - Shell Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSKJlwU-Lt9W",
        "outputId": "9172ba8c-63c3-4296-b3e5-a37b1e810338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing command:\n",
            " dir\n",
            " Volume in drive D is New Volume\n",
            " Volume Serial Number is 16A6-99B1\n",
            "\n",
            " Directory of d:\\GyanPrakashKuswaha\\GenAI\\learn-langchain\\tools-langchain\n",
            "\n",
            "01-12-2025  07.17 PM    <DIR>          .\n",
            "01-12-2025  07.17 PM    <DIR>          ..\n",
            "01-12-2025  08.40 PM            49,074 tools_in_langchain.ipynb\n",
            "               1 File(s)         49,074 bytes\n",
            "               2 Dir(s)  119,961,346,048 bytes free\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools import ShellTool\n",
        "\n",
        "shell_tool = ShellTool()\n",
        "\n",
        "results = shell_tool.invoke('dir')\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkGiksnFOJ3F"
      },
      "source": [
        "## Custom Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ1jNSsrMJZP"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kqzQjm0inH1B"
      },
      "outputs": [],
      "source": [
        "# Step 1 - create a function\n",
        "\n",
        "def multiply(a, b):\n",
        "    \"\"\"Multiply two numbers\"\"\"\n",
        "    return a*b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cUNUMvyVnIXk"
      },
      "outputs": [],
      "source": [
        "# Step 2 - add type hints\n",
        "\n",
        "def multiply(a: int, b:int) -> int:\n",
        "    \"\"\"Multiply two numbers\"\"\"\n",
        "    return a*b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v_OQCXPDOOO5"
      },
      "outputs": [],
      "source": [
        "# Step 3 - add tool decorator\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b:int) -> int:\n",
        "    \"\"\"Multiply two numbers\"\"\"\n",
        "    return a*b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Hyl7U92mOP-4"
      },
      "outputs": [],
      "source": [
        "result = multiply.invoke({\"a\":3, \"b\":5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgb9DJOrOSqG",
        "outputId": "48929af0-6f83-41f3-d107-c90b14af6166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRSajRz6OUWe",
        "outputId": "accb9458-410b-4298-dc34-1c3ddf42aecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "multiply\n",
            "Multiply two numbers\n",
            "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
          ]
        }
      ],
      "source": [
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyFLVLVSOV4Z",
        "outputId": "21e9bf68-58d4-4891-cb04-75c7001f56e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'description': 'Multiply two numbers',\n",
            " 'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
            "                'b': {'title': 'B', 'type': 'integer'}},\n",
            " 'required': ['a', 'b'],\n",
            " 'title': 'multiply',\n",
            " 'type': 'object'}\n"
          ]
        }
      ],
      "source": [
        "pprint(multiply.args_schema.model_json_schema()) # this schema goes to models input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnkkf7XbOqGC"
      },
      "source": [
        "## Method 2 - Using StructuredTool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le0QcJHSOZtx"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'json_schema_extra' from 'pydantic' (d:\\GyanPrakashKuswaha\\GenAI\\learn-langchain\\new-venv\\Lib\\site-packages\\pydantic\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_classic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StructuredTool\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, json_schema_extra\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'json_schema_extra' from 'pydantic' (d:\\GyanPrakashKuswaha\\GenAI\\learn-langchain\\new-venv\\Lib\\site-packages\\pydantic\\__init__.py)"
          ]
        }
      ],
      "source": [
        "from langchain_classic.tools import StructuredTool\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XhQhnCF9OuCx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_7112\\3279971488.py:2: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'required'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  a: int = Field(required=True, description=\"The first number to add\")\n",
            "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_7112\\3279971488.py:3: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'required'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  b: int = Field(required=True, description=\"The second number to add\")\n"
          ]
        }
      ],
      "source": [
        "class MultiplyInput(BaseModel):\n",
        "    a: int = Field(required=True, description=\"The first number to add\")\n",
        "    b: int = Field(required=True, description=\"The second number to add\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "V0emRsp8Ovle"
      },
      "outputs": [],
      "source": [
        "def multiply_func(a: int, b: int) -> int:\n",
        "    return a * b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ym5nmQuaOxJi"
      },
      "outputs": [],
      "source": [
        "multiply_tool = StructuredTool.from_function(\n",
        "    func=multiply_func,\n",
        "    name=\"multiply\",\n",
        "    description=\"Multiply two numbers\",\n",
        "    args_schema=MultiplyInput\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUWsRs6OOy7W",
        "outputId": "c41975ce-e0e4-49a5-f888-ddbb1958b2b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "multiply\n",
            "Multiply two numbers\n",
            "{'a': {'description': 'The first number to add',\n",
            "       'required': True,\n",
            "       'title': 'A',\n",
            "       'type': 'integer'},\n",
            " 'b': {'description': 'The second number to add',\n",
            "       'required': True,\n",
            "       'title': 'B',\n",
            "       'type': 'integer'}}\n"
          ]
        }
      ],
      "source": [
        "result = multiply_tool.invoke({'a':3, 'b':3})\n",
        "\n",
        "print(result)\n",
        "print(multiply_tool.name)\n",
        "print(multiply_tool.description)\n",
        "pprint(multiply_tool.args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m1fr6RpO8vi"
      },
      "source": [
        "## Method 3 - Using BaseTool Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiXpMN0sOzsa"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import BaseTool\n",
        "from typing import Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yl0m79ys625L"
      },
      "outputs": [],
      "source": [
        "# arg schema using pydantic\n",
        "\n",
        "class MultiplyInput(BaseModel):\n",
        "    a: int = Field(required=True, description=\"The first number to add\")\n",
        "    b: int = Field(required=True, description=\"The second number to add\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5pvNLWZPEUd"
      },
      "outputs": [],
      "source": [
        "class MultiplyTool(BaseTool):\n",
        "    name: str = \"multiply\"\n",
        "    description: str = \"Multiply two numbers\"\n",
        "\n",
        "    args_schema: Type[BaseModel] = MultiplyInput\n",
        "\n",
        "    def _run(self, a: int, b: int) -> int:\n",
        "        return a * b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bznB88uQPF4n"
      },
      "outputs": [],
      "source": [
        "multiply_tool = MultiplyTool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RzOFApnPb6K",
        "outputId": "0d4ca09a-4ba1-4210-8a27-0afd833b28c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "multiply\n",
            "Multiply two numbers\n",
            "{'a': {'description': 'The first number to add', 'required': True, 'title': 'A', 'type': 'integer'}, 'b': {'description': 'The second number to add', 'required': True, 'title': 'B', 'type': 'integer'}}\n"
          ]
        }
      ],
      "source": [
        "result = multiply_tool.invoke({'a':3, 'b':3})\n",
        "\n",
        "print(result)\n",
        "print(multiply_tool.name)\n",
        "print(multiply_tool.description)\n",
        "\n",
        "print(multiply_tool.args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNuB9bmZQolv"
      },
      "source": [
        "## Toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFbdDZBiQn9k"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "# Custom tools\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers\"\"\"\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers\"\"\"\n",
        "    return a * b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6tT1z_APgJ1"
      },
      "outputs": [],
      "source": [
        "class MathToolkit:\n",
        "    def get_tools(self):\n",
        "        return [add, multiply]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH6n1A0FRcMc",
        "outputId": "088a8605-3577-4ab6-8604-8ac7a70b16d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "add => Add two numbers\n",
            "multiply => Multiply two numbers\n"
          ]
        }
      ],
      "source": [
        "toolkit = MathToolkit()\n",
        "tools = toolkit.get_tools()\n",
        "\n",
        "for tool in tools:\n",
        "    print(tool.name, \"=>\", tool.description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkfYSzVeReij"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "new-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
